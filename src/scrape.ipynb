{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_url = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/04 23:44:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/04 23:44:44 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(spark_url)\\\n",
    "        .appName('Clean Scraped Data')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_broker = 'localhost:9093'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"11c74ac47ee301629d4f6f3a51e99a60\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=[kafka_broker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for round in range(100):\n",
    "    url = f\"https://api.elsevier.com/content/search/scopus?query=all(Chulalongkorn)&date=2017&view=COMPLETE&apiKey={api_key}&count=25&start={round * 25}\"\n",
    "    headers = {'content-type': 'applicaton/json'}\n",
    "\n",
    "    res = requests.get(url, headers=headers)\n",
    "\n",
    "    entries = res.json()[\"search-results\"][\"entry\"]\n",
    "\n",
    "    scopus_ids = [ entry[\"dc:identifier\"] for entry in entries]\n",
    "    for id in scopus_ids:\n",
    "        url = f\"https://api.elsevier.com/content/abstract/scopus_id/{id}?view=FULL&httpAccept=application%2Fjson&apiKey={api_key}&field=affiliation,author,citedby-count,subject-area,dc:title\"\n",
    "        res = requests.get(url)\n",
    "\n",
    "        df = spark.read.option(\"multiline\", True).json(sc.parallelize([res.text]))\n",
    "\n",
    "        base_path = \"abstracts-retrieval-response\"\n",
    "        try: \n",
    "            is_authors_struct = isinstance(df.schema[base_path].dataType[\"authors\"].dataType[\"author\"].dataType, StructType)\n",
    "            is_affiliations_struct = isinstance(df.schema[base_path].dataType[\"affiliation\"].dataType, StructType)\n",
    "\n",
    "            df = (df.withColumn(\"title\", df[base_path + \".coredata.dc:title\"])\n",
    "            .withColumn(\"id\", F.lit(id))\n",
    "            .withColumn(\"subject-area\",F.col(base_path + \".subject-areas.subject-area.$\"))\n",
    "            .withColumn(\"year\", F.lit(\"2017\"))\n",
    "            .withColumn(\"citation_count\", F.col(base_path + \".coredata.citedby-count\"))\n",
    "            )\n",
    "\n",
    "            if is_authors_struct:\n",
    "                authors_array = F.array(df[base_path + \".authors.author\"])\n",
    "                df = df.withColumn(\"authors\", authors_array)\n",
    "            else:\n",
    "                df = df.withColumn(\"authors\", F.col(base_path + \".authors.author\"))\n",
    "            \n",
    "\n",
    "            if is_affiliations_struct:\n",
    "                affiliations_array = F.array(df[base_path + \".affiliation\"])\n",
    "                df = df.withColumn(\"affiliations\", affiliations_array)\n",
    "            else:\n",
    "                df = df.withColumn(\"affiliations\", F.col(base_path + \".affiliation\"))\n",
    "            \n",
    "\n",
    "\n",
    "            df = df.drop(base_path)\n",
    "            json_res = df.toJSON().first()\n",
    "            producer.send('abstract', json_res.encode('utf-8'))\n",
    "\n",
    "            df.write.mode(\"append\").json(\"../rawData/webscrape\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
